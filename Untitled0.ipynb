{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNvzRslG277G",
        "outputId": "57d0ee8a-f39d-4798-abd3-214f47b09c41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow: 2.19.0\n",
            "GPU available: []\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# 1) Setup & Imports\n",
        "# =========================\n",
        "!pip -q install openpyxl\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "print(\"TensorFlow:\", tf.__version__)\n",
        "print(\"GPU available:\", tf.config.list_physical_devices('GPU'))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 2) Mount Google Drive\n",
        "# =========================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to your folder in Drive\n",
        "FOLDER_PATH = \"/content/drive/MyDrive/Colab Notebooks/Pyton basic\"\n",
        "\n",
        "# Expected file name (change if needed)\n",
        "FILE_NAME = \"Example data.xlsx\"\n",
        "\n",
        "EXCEL_PATH = os.path.join(FOLDER_PATH, FILE_NAME)\n",
        "\n",
        "# Smart check: if file not found, show folder contents\n",
        "if not os.path.exists(EXCEL_PATH):\n",
        "    print(f\"‚ùå File not found: {EXCEL_PATH}\")\n",
        "    print(\"üîé Listing files in folder instead:\")\n",
        "    print(\"=\"*60)\n",
        "    for f in os.listdir(FOLDER_PATH):\n",
        "        print(f)\n",
        "else:\n",
        "    print(f\"‚úÖ File found: {EXCEL_PATH}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "QoBVb4973LLN",
        "outputId": "95d263cf-8d5c-4341-e16c-fc2c7fd66d67"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2329517774.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# =========================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Path to your folder in Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 3) Load & Inspect Data\n",
        "# =========================\n",
        "df = pd.read_excel(EXCEL_PATH, sheet_name=SHEET_NAME, engine='openpyxl')\n",
        "\n",
        "# Normalize column names for easy matching\n",
        "df.columns = [c.strip() for c in df.columns]\n",
        "cols_lower = {c.lower(): c for c in df.columns}\n",
        "\n",
        "# Identify date & target columns (case-insensitive)\n",
        "DATE_COL = None\n",
        "for candidate in ['date', 'timestamp', 'datetime']:\n",
        "    if candidate in cols_lower:\n",
        "        DATE_COL = cols_lower[candidate]; break\n",
        "\n",
        "TARGET_COL = None\n",
        "for candidate in ['close', 'adj close', 'adj_close', 'closing price', 'price']:\n",
        "    if candidate in cols_lower:\n",
        "        TARGET_COL = cols_lower[candidate]; break\n",
        "\n",
        "if DATE_COL is None:\n",
        "    raise ValueError(\"Could not find a date column (e.g., 'Date'). Please rename or set DATE_COL manually.\")\n",
        "if TARGET_COL is None:\n",
        "    raise ValueError(\"Could not find a target price column (e.g., 'Close' or 'Adj Close'). Please rename or set TARGET_COL manually.\")\n",
        "\n",
        "# Basic cleanup\n",
        "df[DATE_COL] = pd.to_datetime(df[DATE_COL], errors='coerce')\n",
        "df = df.dropna(subset=[DATE_COL, TARGET_COL]).sort_values(DATE_COL).reset_index(drop=True)\n",
        "\n",
        "print(\"Using columns:\")\n",
        "print(\"Date column  :\", DATE_COL)\n",
        "print(\"Target column:\", TARGET_COL)\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "lJWE7cIU3UMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 4) Optional: add extra features\n",
        "#    (You can expand this block with your own indicators)\n",
        "# =========================\n",
        "# Simple technicals: returns and moving averages\n",
        "df['ret_1'] = df[TARGET_COL].pct_change()\n",
        "df['ma_5']  = df[TARGET_COL].rolling(5).mean()\n",
        "df['ma_10'] = df[TARGET_COL].rolling(10).mean()\n",
        "df['vol_5'] = df[TARGET_COL].rolling(5).std()\n",
        "\n",
        "# Drop initial NaNs from indicators\n",
        "df = df.dropna().reset_index(drop=True)\n",
        "\n",
        "# Feature set: you can add more columns here\n",
        "FEATURE_COLS = [TARGET_COL, 'ret_1', 'ma_5', 'ma_10', 'vol_5']\n",
        "\n",
        "data = df[FEATURE_COLS].values.astype(np.float32)\n",
        "dates = df[DATE_COL].values\n"
      ],
      "metadata": {
        "id": "YXKbhuMm3V70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 5) Scale & Create Sequences\n",
        "# =========================\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "data_scaled = scaler.fit_transform(data)\n",
        "\n",
        "SEQ_LEN = 60   # past days to look at\n",
        "HORIZON = 1    # predict next day\n",
        "def make_sequences(arr, seq_len=60, horizon=1, target_index=0):\n",
        "    X, y = [], []\n",
        "    for i in range(seq_len, len(arr) - horizon + 1):\n",
        "        X.append(arr[i-seq_len:i, :])\n",
        "        y.append(arr[i + horizon - 1, target_index])  # target is 'Close' scaled\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "X, y = make_sequences(data_scaled, SEQ_LEN, HORIZON, target_index=0)\n",
        "seq_dates = dates[SEQ_LEN - 1: len(dates) - HORIZON + 1]  # align dates with X/y\n",
        "\n",
        "print(\"X shape:\", X.shape, \"y shape:\", y.shape)\n"
      ],
      "metadata": {
        "id": "1Kwg-XkN3Yqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 6) Train/Validation/Test Split (time-series safe)\n",
        "# =========================\n",
        "total = len(X)\n",
        "train_end = int(0.7 * total)\n",
        "val_end   = int(0.85 * total)\n",
        "\n",
        "X_train, y_train = X[:train_end], y[:train_end]\n",
        "X_val,   y_val   = X[train_end:val_end], y[train_end:val_end]\n",
        "X_test,  y_test  = X[val_end:], y[val_end:]\n",
        "dates_test       = seq_dates[val_end:]\n",
        "\n",
        "print(f\"Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")\n"
      ],
      "metadata": {
        "id": "zN_97NMl3agv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 7) Build LSTM Model\n",
        "# =========================\n",
        "tf.keras.backend.clear_session()\n",
        "model = Sequential([\n",
        "    LSTM(128, return_sequences=True, input_shape=(X.shape[1], X.shape[2])),\n",
        "    Dropout(0.2),\n",
        "    LSTM(64, return_sequences=False),\n",
        "    Dropout(0.2),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1)  # next-day close (scaled)\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "              loss='mse')\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "YhV7uq4y3dQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 8) Train\n",
        "# =========================\n",
        "ckpt_path = '/content/best_lstm.h5'\n",
        "callbacks = [\n",
        "    ModelCheckpoint(ckpt_path, monitor='val_loss', save_best_only=True, verbose=1),\n",
        "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1),\n",
        "    ReduceLROnPlateau(monitor='val_loss', patience=5, factor=0.5, verbose=1, min_lr=1e-5)\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=100,\n",
        "    batch_size=64,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "uRDG2cTd3e-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 9) Evaluate (on Test)\n",
        "# =========================\n",
        "pred_test_scaled = model.predict(X_test).flatten()\n",
        "true_test_scaled = y_test.flatten()\n",
        "\n",
        "def invert_target(scaled_series, scaler, feature_index=0):\n",
        "    filler = np.zeros((len(scaled_series), scaler.n_features_in_), dtype=np.float32)\n",
        "    filler[:, feature_index] = scaled_series\n",
        "    inv = scaler.inverse_transform(filler)\n",
        "    return inv[:, feature_index]\n",
        "\n",
        "pred_test = invert_target(pred_test_scaled, scaler, 0)\n",
        "true_test = invert_target(true_test_scaled, scaler, 0)\n",
        "\n",
        "mae  = mean_absolute_error(true_test, pred_test)\n",
        "mse  = mean_squared_error(true_test, pred_test)\n",
        "rmse = np.sqrt(mse)\n",
        "r2   = r2_score(true_test, pred_test)\n",
        "\n",
        "print(f\"Test MAE : {mae:,.4f}\")\n",
        "print(f\"Test RMSE: {rmse:,.4f}\")\n",
        "print(f\"Test R¬≤  : {r2:,.4f}\")\n"
      ],
      "metadata": {
        "id": "xUwBo7N03gcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 10) Plot Predictions vs Actual (fixed)\n",
        "# =========================\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.plot(dates_test[:len(true_test)], true_test, label='Actual')\n",
        "plt.plot(dates_test[:len(pred_test)], pred_test, label='Predicted')\n",
        "plt.title('LSTM ‚Äî Next-Day Close (Test Set)')\n",
        "plt.xlabel('Date'); plt.ylabel('Price')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "F9VS6J9m3ig7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 11) Save Model & Scaler (optional)\n",
        "# =========================\n",
        "model.save('/content/lstm_stock_model.keras')\n",
        "import joblib\n",
        "joblib.dump(scaler, '/content/feature_scaler.pkl')\n",
        "\n",
        "print(\"Saved:\", '/content/lstm_stock_model.keras', 'and', '/content/feature_scaler.pkl')\n"
      ],
      "metadata": {
        "id": "TZ8F2HoD3kJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 12) Make a One-Step-Ahead Forecast for the most recent window\n",
        "# =========================\n",
        "last_window = data_scaled[-SEQ_LEN:]  # last seq_len rows\n",
        "last_window = np.expand_dims(last_window, axis=0)\n",
        "next_scaled = model.predict(last_window).flatten()[0]\n",
        "next_pred   = invert_target(np.array([next_scaled]), scaler, feature_index=0)[0]\n",
        "\n",
        "print(\"Most recent available date:\", df[DATE_COL].iloc[-1].date())\n",
        "print(\"Next-day predicted Close  :\", round(float(next_pred), 4))\n"
      ],
      "metadata": {
        "id": "GMuBNKGa3m6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TARGET_COL = 'Adj Close'\n"
      ],
      "metadata": {
        "id": "qnP9idfz3nk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Generate Buy/Sell/Hold Signals\n",
        "# =========================\n",
        "\n",
        "signals = []\n",
        "\n",
        "for i in range(len(future_df)):\n",
        "    if i == 0:\n",
        "        signals.append(\"HOLD\")  # first prediction = no previous day\n",
        "    else:\n",
        "        if future_df[\"Predicted_Close\"].iloc[i] > future_df[\"Predicted_Close\"].iloc[i-1]:\n",
        "            signals.append(\"BUY\")\n",
        "        elif future_df[\"Predicted_Close\"].iloc[i] < future_df[\"Predicted_Close\"].iloc[i-1]:\n",
        "            signals.append(\"SELL\")\n",
        "        else:\n",
        "            signals.append(\"HOLD\")\n",
        "\n",
        "# Add to DataFrame\n",
        "future_df[\"Signal\"] = signals\n",
        "\n",
        "# Show table\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "display(future_df)\n",
        "\n",
        "# Save to CSV for Power BI\n",
        "future_df.to_csv(\"/content/Stock_Forecast_Signals.csv\", index=False)\n",
        "print(\"‚úÖ File saved with Buy/Sell/Hold signals: Stock_Forecast_Signals.csv\")\n"
      ],
      "metadata": {
        "id": "1YSzYD__9lI0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}